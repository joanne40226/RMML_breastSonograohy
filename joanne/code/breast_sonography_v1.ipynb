{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "breast_sonography_v1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Import Packages**"
      ],
      "metadata": {
        "id": "dkaBo4E5Tz3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "import numpy as np\n",
        "import csv\n",
        "from numpy.core.defchararray import encode\n",
        "from numpy.core.numeric import NaN\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix,  f1_score\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "91C3hxL4URnH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Up Sampling**"
      ],
      "metadata": {
        "id": "FOTvKsRCoJfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upsampling(X_train, y_train):\n",
        "  # upsampling on training data only\n",
        "  from imblearn.over_sampling import SMOTE\n",
        "  smt = SMOTE(random_state = 1126)\n",
        "  X_train, y_train = smt.fit_resample(X_train, y_train)\n",
        "  from collections import Counter\n",
        "  print(sorted(Counter(y_train).items()))\n",
        "  return X_train, y_train"
      ],
      "metadata": {
        "id": "O5PSgd3FoND_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read Data from Google Drive**"
      ],
      "metadata": {
        "id": "iGTci5RyfDn8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNBNFHTLRo5z",
        "outputId": "12b0da1e-fd00-4dc2-ae09-d956d51a7684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/gdrive') # 此處需要登入google帳號\n",
        "# 獲取授權碼之後輸入即可連動雲端硬碟\n",
        "#!\"/content/gdrive/MyDrive/breast/BreastSonor7Features.csv\"\n",
        "train_path = \"/content/gdrive/MyDrive/breast/BreastSonor7Features.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Loader**"
      ],
      "metadata": {
        "id": "uKMhoajqm_qL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "def data_loader(train_path):\n",
        "    data = pd.read_csv(train_path)\n",
        "    data_top = list(data.columns)\n",
        "    with open(train_path, 'r') as fp:     \n",
        "        data_train = list(csv.reader(fp))\n",
        "        data_label = data_train\n",
        "        data_train = np.array(data_train[1:])[:, 0:7]\n",
        "        data_label = np.array(data_label[1:])[:, 7]    \n",
        "    return data_train, data_label"
      ],
      "metadata": {
        "id": "VfswAB2mdi8P"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RMSE**"
      ],
      "metadata": {
        "id": "EfFVTA8frTeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def RMSE(prediction, ground):\n",
        "  length = len(prediction)\n",
        "  sum = 0\n",
        "  RMSE = 0\n",
        "  for i in range(length):\n",
        "    sum += (float(prediction[i]) - float(ground[i]))**2\n",
        "  sum /= length\n",
        "  RMSE = math.sqrt(sum)\n",
        "  return RMSE"
      ],
      "metadata": {
        "id": "-lvrldtarV9Z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**COLOR**"
      ],
      "metadata": {
        "id": "0P19oF76iZ8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CRED = '\\033[91m'\n",
        "CEND = '\\033[0m'"
      ],
      "metadata": {
        "id": "gEbHxHUSibD2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes classifier**"
      ],
      "metadata": {
        "id": "Hypm9Ji6pdQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NB(X_train, X_val, y_train, y_val):\n",
        "    from sklearn.naive_bayes import GaussianNB\n",
        "    gnb = GaussianNB().fit(X_train, y_train)\n",
        "    val_predictions = gnb.predict(X_val)\n",
        "    #RMSE\n",
        "    NB_RMSE = 0\n",
        "    NB_RMSE = RMSE(val_predictions, y_val)\n",
        "    print(CRED +\"NB RMSE = \"+CEND,NB_RMSE)\n",
        "    # Validation accuracy\n",
        "    accuracy = gnb.score(X_val, y_val)\n",
        "    #print('NB accuracy')\n",
        "    #print(accuracy)\n",
        "    # Validation confusion matrix\n",
        "    cm = confusion_matrix(y_val, val_predictions)\n",
        "    #print('NB CFmap')\n",
        "    #print(cm)\n",
        "    numOfBigError = 0\n",
        "    for i in range(len(y_val)):\n",
        "      error = abs(float(y_val[i])-float(val_predictions[i]))\n",
        "      if error > 1:\n",
        "        numOfBigError+=1\n",
        "    print(\"num of error > 1 = \",numOfBigError)\n",
        "    #testing\n",
        "    #test_predictions = gnb.predict(x_test)\n",
        "    return True"
      ],
      "metadata": {
        "id": "0GnABl3Fpa8s"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNN**"
      ],
      "metadata": {
        "id": "soB-u8RbpWzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def KNN(X_train, X_val, y_train, y_val):\n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "    knn = KNeighborsClassifier(n_neighbors = 7).fit(X_train, y_train)\n",
        "    print(knn)\n",
        "    # model accuracy for X_test \n",
        "    accuracy = knn.score(X_val, y_val)\n",
        "    #print('KNN accuracy')\n",
        "    #print(accuracy)\n",
        "    # creating a confusion matrix\n",
        "    knn_predictions = knn.predict(X_val)\n",
        "    #RMSE\n",
        "    KNN_RMSE = 0\n",
        "    KNN_RMSE = RMSE(knn_predictions, y_val)\n",
        "    print(CRED +\"KNN RMSE = \"+CEND,KNN_RMSE)\n",
        "    cm = confusion_matrix(y_val, knn_predictions)\n",
        "    numOfBigError = 0\n",
        "    for i in range(len(y_val)):\n",
        "      error = abs(float(y_val[i])-float(knn_predictions[i]))\n",
        "      if error > 1:\n",
        "        numOfBigError+=1\n",
        "    print(\"num of error > 1 = \",numOfBigError)\n",
        "    #print('KNN CFmap')\n",
        "    #print(cm)\n",
        "    #testing\n",
        "    #test_predictions = knn.predict(x_test)\n",
        "    return True"
      ],
      "metadata": {
        "id": "8C9fBo5IpYb7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**"
      ],
      "metadata": {
        "id": "-cQ9wWquo3rX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RF(X_train, X_val, y_train, y_val, grid = False):\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "    #grid search\n",
        "    if grid == True:\n",
        "        rf = RandomForestClassifier()\n",
        "        parameters = {'n_estimators':range(100, 1000, 100)}\n",
        "        clf = GridSearchCV(rf, parameters)\n",
        "        clf.fit(X_train, y_train)\n",
        "        rf = clf.best_estimator_\n",
        "\n",
        "    if grid == False:\n",
        "        rf = RandomForestClassifier()\n",
        "        rf.fit(X_train, y_train)\n",
        "    \n",
        "    #result\n",
        "    rf_predictions = rf.predict(X_val)\n",
        "    #RMSE\n",
        "    RF_RMSE = 0\n",
        "    RF_RMSE = RMSE(rf_predictions, y_val)\n",
        "    error = 0\n",
        "    numOfBigError = 0\n",
        "    for i in range(len(y_val)):\n",
        "      #print(\"truth \",i,\" = \",y_val[i])\n",
        "      #print(\"prediction \",i,\" = \",rf_predictions[i])\n",
        "      error = abs(float(y_val[i])-float(rf_predictions[i]))\n",
        "      if error > 1:\n",
        "        numOfBigError+=1\n",
        "        #print(CRED+\"big error = \"+CEND, error)\n",
        "    print(CRED+\"RF RMSE = \"+CEND,RF_RMSE)\n",
        "    print(\"num of error > 1 = \",numOfBigError)\n",
        "    accuracy = rf.score(X_val, y_val)\n",
        "    #print('RF accuracy')\n",
        "    #print(accuracy)\n",
        "    cm = confusion_matrix(y_val, rf_predictions)\n",
        "    #print('RF CFmap')\n",
        "    #print(cm)\n",
        "    #print('RF f1 score')\n",
        "    #print(f1_score(y_val, rf_predictions, average = 'macro'))\n",
        "    #testing\n",
        "    #test_predictions = rf.predict(x_test)\n",
        "    return True"
      ],
      "metadata": {
        "id": "uaKFThbgo1tg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GradientBoosting**"
      ],
      "metadata": {
        "id": "SMkNnJchm8Up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GradientBoosting(X_train, X_val, y_train, y_val, grid = False):\n",
        "    from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "    if grid == True:\n",
        "        gb = GradientBoostingClassifier()\n",
        "        parameters = {'n_estimators': range(100, 500, 100),\n",
        "                      'learning_rate': [0.01, 0.05, 0.1, 0.5, 1]\n",
        "                      }\n",
        "        clf = GridSearchCV(gb, parameters)\n",
        "        clf.fit(X_train, y_train)\n",
        "        print(clf.best_params_)\n",
        "        gb = clf.best_estimator_\n",
        "\n",
        "    else:\n",
        "        gb = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.1, random_state = 1126)\n",
        "        gb = Pipeline([ #('pca', PCA(n_components = 5)),\n",
        "                        ('clf', gb)\n",
        "                    ])\n",
        "        gb.fit(X_train, y_train)\n",
        "\n",
        "    # Validation\n",
        "    accuracy = gb.score(X_val, y_val)\n",
        "    #print('GB accuracy')\n",
        "    #print(accuracy)\n",
        "    # creating a confusion matrix\n",
        "    gb_predictions = gb.predict(X_val)\n",
        "    cm = confusion_matrix(y_val, gb_predictions)\n",
        "    #RMSE\n",
        "    GB_RMSE = 0\n",
        "    GB_RMSE = RMSE(gb_predictions, y_val)\n",
        "    print(CRED+\"GB RMSE = \"+CEND,GB_RMSE)\n",
        "    numOfBigError = 0\n",
        "    for i in range(len(y_val)):\n",
        "      error = abs(float(y_val[i])-float(gb_predictions[i]))\n",
        "      if error > 1:\n",
        "        numOfBigError+=1\n",
        "    print(\"num of error > 1 = \",numOfBigError)\n",
        "    '''\n",
        "    #print('GB CFmap')\n",
        "    #print(cm)\n",
        "    #print('GB f1 score')\n",
        "    #print(f1_score(y_val, gb_predictions, average = 'macro'))\n",
        "    # add validation-set into sub-training set\n",
        "    X_trainval = np.vstack((np.array(X_train), np.array(X_val)))\n",
        "    y_trainval = np.hstack((np.array(y_train), np.array(y_val)))\n",
        "\n",
        "    # retraining w/ full training set\n",
        "    if grid == True:\n",
        "        gb = GradientBoostingClassifier(clf.best_params_)\n",
        "    else:\n",
        "        gb = GradientBoostingClassifier(n_estimators = 400, learning_rate = 0.5, random_state = 1126)\n",
        "\n",
        "    gb.fit(X_trainval, y_trainval)\n",
        "    # testing\n",
        "    #test_predictions = gb.predict(x_test)\n",
        "    '''\n",
        "    return True"
      ],
      "metadata": {
        "id": "u7r1k0ildFHg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read in data**"
      ],
      "metadata": {
        "id": "67iK1HMSm4mB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_trainval, data_label = data_loader(train_path)\n",
        "print(data_trainval)\n",
        "print(data_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWNc2ePDUbth",
        "outputId": "7543d212-2678-44f1-9f39-ad70b368e970"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['15' '5' '0.05' ... '0.009442287056' '1.755375862' '26']\n",
            " ['15' '5' '0.1' ... '0.06622273196' '5.810700061' '32']\n",
            " ['15' '5' '0.15' ... '0.137937152' '8.87464948' '30']\n",
            " ...\n",
            " ['9' '9' '0.55' ... '0.05064993443' '9.984683966' '12']\n",
            " ['9' '9' '0.6' ... '0.08643025264' '10.77140081' '11']\n",
            " ['9' '9' '0.65' ... '0.136791564' '11.37730887' '10']]\n",
            "['8.983061726' '5.480890386' '4.99804434' '9.003461097' '9.003469731'\n",
            " '9.003469731' '9.003469731' '3.845430564' '2.025254121' '5.02886453'\n",
            " '6.678104153' '9.004432306' '9.003458744' '9.00346972' '9.003469396'\n",
            " '9.003469731' '9.003469731' '9.003469416' '9.002893666' '9.020697043'\n",
            " '8.987546167' '9.00346973' '9.003469731' '6.004890401' '6.004890536'\n",
            " '6.005284697' '8.874492671' '8.921157369' '8.993892457' '9.000166171'\n",
            " '9.6480695' '7.870843864' '7.380105246' '9.003469731' '9.003469731'\n",
            " '9.003469731' '9.003469731' '9.003469731' '9.003468423' '9.001694384'\n",
            " '9.01925677' '9.002572673' '9.00346088' '9.003469731' '9.003469731'\n",
            " '9.003469731' '9.003469731' '9.003469731' '9.003469731' '9.003469731'\n",
            " '9.003469731' '9.00346973' '9.003469731' '9.003467242' '9.003469713'\n",
            " '9.00346973' '9.003469731' '9.00346973' '9.003469699' '9.00284585'\n",
            " '5.029768601' '4.996380301' '9.003469731' '9.003469731' '9.003469731'\n",
            " '9.003469719' '9.003463854' '8.995843749' '8.969470955' '9.003260285'\n",
            " '3.776452964' '9.003469731' '9.003469731' '9.003469731' '9.003469731'\n",
            " '9.003469731' '9.003469731' '9.003469731' '9.00346973' '9.003469327'\n",
            " '9.003423437' '9.003469731' '9.003469731' '9.003469731' '9.003469731'\n",
            " '9.003469731' '9.003469731' '9.003469731' '8.972870375' '5.049806232'\n",
            " '4.99732036' '4.997300178' '4.997322218' '5.113796238' '9.002980572'\n",
            " '2.031923405' '1.998720752' '1.998720256' '1.998712748' '1.99864267'\n",
            " '1.99818226' '4.933723094' '4.973378359' '4.365919586' '4.521067097'\n",
            " '9.003469731' '9.003469728' '9.0030427' '5.039510867' '4.997297749'\n",
            " '4.997210798' '4.996703021' '4.956073384' '4.948690792' '4.660788225'\n",
            " '6.004890401' '6.004890416' '6.005463511' '5.003203741' '4.960012785'\n",
            " '4.997193305' '4.996445815' '4.977159919' '4.724963629' '4.166974521'\n",
            " '3.575676491' '3.296714888' '9.003469731' '9.003469731' '9.003469676'\n",
            " '8.998268773' '4.99743002' '4.997287278' '4.99706083' '4.991010325'\n",
            " '4.988909985' '4.870154369' '9.003469731' '9.003469731' '9.003469731'\n",
            " '9.003263597' '5.063608849' '4.997318711' '4.981825301' '3.471826101'\n",
            " '8.987008975' '4.997896644' '4.997285869' '4.9818628' '3.036882524'\n",
            " '2.033228886' '1.995406676' '1.977303941' '1.985253779' '2.026590511'\n",
            " '4.745115126' '2.105137803' '1.998721774' '1.998720474' '1.998711797'\n",
            " '1.998570302' '4.920203377' '2.021881205' '4.951122922' '4.742165787'\n",
            " '4.612518274' '1.998717695' '1.998621723' '1.997371367' '1.992046901'\n",
            " '1.979109543' '1.959039382' '1.9341916' '1.890353317' '6.004890401'\n",
            " '6.004890378' '6.004326536' '3.726472173' '4.993510741' '4.997040453'\n",
            " '4.99669631' '4.979187063' '4.772757119' '4.149202651' '6.008721419'\n",
            " '9.003465032' '1.998862455' '2.027361598' '2.002508405' '2.003660497'\n",
            " '1.993574802' '2.804413677' '4.879008416' '5.411587075' '9.08919074'\n",
            " '4.997479591' '4.997157843' '1.998256131' '1.995558453' '1.987566463']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split data**"
      ],
      "metadata": {
        "id": "LS5-8uD0psnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(data_trainval, data_label, random_state = 1126, train_size = 0.8)\n",
        "\n",
        "'''\n",
        "#upsampling\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smt = SMOTE(random_state = 1126)\n",
        "X_train, y_train = smt.fit_resample(X_train, y_train)\n",
        "from collections import Counter\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "3SOOTk4Hnrv8",
        "outputId": "3f3c207c-43a4-4357-dd1f-af43d4db5718"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#upsampling\\nfrom imblearn.over_sampling import SMOTE\\nsmt = SMOTE(random_state = 1126)\\nX_train, y_train = smt.fit_resample(X_train, y_train)\\nfrom collections import Counter\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trainning Prediction**"
      ],
      "metadata": {
        "id": "6yQU-UDxpvxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"NB Predicrion\")\n",
        "predictions_NB = NB(X_train, X_val, y_train, y_val)\n",
        "\n",
        "print(\"\\nKNN Predicrion\")\n",
        "predictions_KNN = KNN(X_train, X_val, y_train, y_val)\n",
        "\n",
        "print(\"\\nRF Predicrion\")\n",
        "predictions_RF = RF(X_train, X_val, y_train, y_val, False)\n",
        "\n",
        "print(\"\\nGB Predicrion\")\n",
        "predictions_GB = GradientBoosting(X_train, X_val, y_train, y_val, False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkG_WmqyoVkU",
        "outputId": "8533d6f2-5d05-47a2-c020-7670f8da3173"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NB Predicrion\n",
            "\u001b[91mNB RMSE = \u001b[0m 3.957957019387441\n",
            "num of error > 1 =  22\n",
            "\n",
            "KNN Predicrion\n",
            "KNeighborsClassifier(n_neighbors=7)\n",
            "\u001b[91mKNN RMSE = \u001b[0m 3.080404477289863\n",
            "num of error > 1 =  18\n",
            "\n",
            "RF Predicrion\n",
            "\u001b[91mRF RMSE = \u001b[0m 1.759337778446933\n",
            "num of error > 1 =  12\n",
            "\n",
            "GB Predicrion\n",
            "\u001b[91mGB RMSE = \u001b[0m 2.421539074103847\n",
            "num of error > 1 =  18\n"
          ]
        }
      ]
    }
  ]
}